# Auto-generated DAG for Workflow: frontend_test_workflow
# Workflow ID: f61cf207-2240-4c00-91d6-7ad1763b86fb
# Generated by MLOps Workflow System

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

# DAG default arguments
default_args = {
    'owner': 'mlops',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
}

# Create DAG
with DAG(
    dag_id='workflow_f61cf207-2240-4c00-91d6-7ad1763b86fb',
    default_args=default_args,
    description='Workflow created via frontend integration test',
    schedule_interval='@hourly',
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['mlops', 'auto-generated', 'frontend_test_workflow']
) as dag:


    # Task: feature_engineering
    def feature_engineering_func(**context):
        """
        Auto-generated task function for: feature_engineering
        """
        # User-defined Python code
        import pandas as pd
        import numpy as np
        print("Feature engineering started...")
        data = context["ti"].xcom_pull(task_ids="load_data", key="dataset")
        print(f"Processing {len(data['feature1'])} samples")
        # Create interaction features
        feature3 = np.array(data['feature1']) * np.array(data['feature2'])
        print(f"Created interaction feature with shape: {feature3.shape}")
        context["ti"].xcom_push(key="features_count", value=3)
        print("[OK] Feature engineering completed")

    feature_engineering = PythonOperator(
        task_id='feature_engineering',
        python_callable=feature_engineering_func,
        op_kwargs={},
        retries=2,
        retry_delay=timedelta(seconds=300),
        provide_context=True,
    )

    # Task: load_data
    def load_data_func(**context):
        """
        Auto-generated task function for: load_data
        """
        # User-defined Python code
        import pandas as pd
        import numpy as np
        print("Loading data...")
        data = {
            'feature1': np.random.rand(100),
            'feature2': np.random.rand(100),
            'target': np.random.randint(0, 2, 100)
        }
        df = pd.DataFrame(data)
        print(f"Loaded {len(df)} samples")
        context["ti"].xcom_push(key="dataset", value=data)
        print("[OK] Data loading completed")

    load_data = PythonOperator(
        task_id='load_data',
        python_callable=load_data_func,
        op_kwargs={},
        retries=2,
        retry_delay=timedelta(seconds=300),
        provide_context=True,
    )

    # Task: train_model
    def train_model_func(**context):
        """
        Auto-generated task function for: train_model
        """
        # User-defined Python code
        from sklearn.ensemble import RandomForestClassifier
        import numpy as np
        print("Model training started...")
        data = context["ti"].xcom_pull(task_ids="load_data", key="dataset")
        features_count = context["ti"].xcom_pull(task_ids="feature_engineering", key="features_count")
        print(f"Training with {features_count} features")
        X = np.column_stack([data['feature1'], data['feature2']])
        y = np.array(data['target'])
        model = RandomForestClassifier(n_estimators=10, random_state=42)
        model.fit(X, y)
        score = model.score(X, y)
        print(f"Model trained! Training accuracy: {score:.4f}")
        context["ti"].xcom_push(key="model_accuracy", value=score)
        print("[OK] Model training completed")

    train_model = PythonOperator(
        task_id='train_model',
        python_callable=train_model_func,
        op_kwargs={},
        retries=1,
        retry_delay=timedelta(seconds=300),
        provide_context=True,
    )


    # Task Dependencies



    load_data >> feature_engineering







    feature_engineering >> train_model



# Auto-generated DAG for Workflow: git_ml_pipeline
# Workflow ID: 85ac11db-26dc-4e29-a21d-4eff129f8dc1
# Generated by MLOps Workflow System

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import os
import sys
import tempfile
import subprocess
import importlib.util

# Git repository information
GIT_REPOSITORY = 'https://github.com/your-org/ml-training-repo.git'
GIT_BRANCH = 'main'

# Helper function to execute Git-based tasks
def execute_git_task(repo_url, branch, script_path, function_name, **context):
    """
    Clone Git repository and execute function from script
    """
    import json
    import numpy as np

    # Helper function to serialize data for XCom
    def serialize_for_xcom(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: serialize_for_xcom(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [serialize_for_xcom(item) for item in obj]
        return obj

    with tempfile.TemporaryDirectory() as tmpdir:
        print(f"Cloning repository: {repo_url}, branch: {branch}")

        # Clone Git repository
        subprocess.run(
            ['git', 'clone', '--depth', '1', '--branch', branch, repo_url, tmpdir],
            check=True,
            capture_output=True,
            text=True
        )

        # Install requirements if exists
        requirements_path = os.path.join(tmpdir, 'requirements.txt')
        if os.path.exists(requirements_path):
            print(f"Installing requirements from {requirements_path}")
            subprocess.run(
                [sys.executable, '-m', 'pip', 'install', '-r', requirements_path],
                check=True,
                capture_output=True,
                text=True
            )

        # Import and execute function from script
        script_full_path = os.path.join(tmpdir, script_path)
        print(f"Loading script: {script_full_path}")

        spec = importlib.util.spec_from_file_location("user_module", script_full_path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)

        # Get and execute the function
        if not hasattr(module, function_name):
            raise AttributeError(f"Function '{function_name}' not found in {script_path}")

        func = getattr(module, function_name)
        print(f"Executing function: {function_name}")

        # Pass context and params to the function
        result = func(context=context, **context.get('params', {}))

        # Serialize result if needed
        if result is not None:
            result = serialize_for_xcom(result)

        return result

# DAG default arguments
default_args = {
    'owner': 'mlops',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
}

# Create DAG
with DAG(
    dag_id='workflow_85ac11db-26dc-4e29-a21d-4eff129f8dc1',
    default_args=default_args,
    description='ML Pipeline using Git repository',
    schedule_interval='@daily',
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['mlops', 'auto-generated', 'git_ml_pipeline']
) as dag:


    # Task: evaluate_model

    # Inline code task: executes Python code directly
    def evaluate_model_func(**context):
        """
        Auto-generated task function for: evaluate_model
        """
        import json
        import numpy as np

        # Helper function to serialize data for XCom
        def serialize_for_xcom(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: serialize_for_xcom(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [serialize_for_xcom(item) for item in obj]
            return obj

        # Execute user-defined code
        user_code = r'''def evaluate_model():
    print('Evaluating model...')
    return {'status': 'success', 'accuracy': 0.95}'''

        # Create a local namespace for execution
        local_vars = {'context': context, '__builtins__': __builtins__}

        # Execute the user code
        exec(user_code, local_vars)

        # If user defined a function with the same name as task_id, call it
        if 'evaluate_model' in local_vars and callable(local_vars['evaluate_model']):
            result = local_vars['evaluate_model']()
            # Serialize result if it contains numpy arrays
            if result is not None:
                result = serialize_for_xcom(result)
            return result


    evaluate_model = PythonOperator(
        task_id='evaluate_model',
        python_callable=evaluate_model_func,
        op_kwargs={},
        retries=1,
        retry_delay=timedelta(seconds=300),
        provide_context=True,
    )

    # Task: train_model

    # Git-based task: executes function from Git repository
    def train_model_func(**context):
        """
        Git-based task function for: train_model
        Repository: https://github.com/your-org/ml-training-repo.git
        Script: src/train.py
        Function: train_model
        """
        return execute_git_task(
            repo_url=GIT_REPOSITORY,
            branch=GIT_BRANCH,
            script_path='src/train.py',
            function_name='train_model',
            **context
        )


    train_model = PythonOperator(
        task_id='train_model',
        python_callable=train_model_func,
        op_kwargs={'epochs': 100, 'batch_size': 32},
        retries=2,
        retry_delay=timedelta(seconds=600),
        provide_context=True,
    )


    # Task Dependencies



    train_model >> evaluate_model




